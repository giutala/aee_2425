{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM for Predicting PV energy generation   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling and manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Deep learning (LSTM)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import numpy as np\n",
    "# Plotting and visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "file_path = 'solar_data_with_temperature_adjusted_irradiance.csv'\n",
    "data = pd.read_csv(\n",
    "    file_path,\n",
    "    index_col=[0],  # Use 'time' as the index\n",
    "    parse_dates=[0]  # Parse the 'time' column as datetime\n",
    ").drop(columns=['Year', 'Month', 'Day', 'Hour', 'Minute'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = data.index[int(len(data) * 0.7)]\n",
    "\n",
    "train = data.loc[data.index <= split].copy()\n",
    "test = data.loc[data.index > split].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 2: Separate the features (X) and the target (y)\n",
    "def create_features(data, label=None):\n",
    "    X = data[['GHI', 'DNI', 'DHI', 'Temperature']]  # Features\n",
    "    if label:\n",
    "        y = data[label]  # Target variable\n",
    "        return X, y\n",
    "    return X\n",
    "\n",
    "X_train, y_train = create_features(train, label='Tilted Irradiance (Adjusted)')\n",
    "X_test, y_test = create_features(test, label='Tilted Irradiance (Adjusted)')\n",
    "\n",
    "# Step 6: Apply ColumnTransformer for preprocessing to the dataset\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['GHI', 'DNI', 'DHI', 'Temperature']),  # Scale numerical features\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Scale the data (apply transformation on both training and testing data)\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "\n",
    "# Reshape the data for LSTM (3D array)\n",
    "# For LSTM, we need a 3D shape (samples, time_steps, features), with time_steps = 1 for each sample in this case.\n",
    "X_train_scaled = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])  # 1 timestep\n",
    "X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])  # 1 timestep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giuli\\AppData\\Local\\Temp\\ipykernel_29256\\35471574.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_cv, y_val_cv = y_train[train_idx], y_train[val_idx]\n",
      "c:\\Users\\giuli\\Repositories\\aee_2425\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giuli\\AppData\\Local\\Temp\\ipykernel_29256\\35471574.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_cv, y_val_cv = y_train[train_idx], y_train[val_idx]\n",
      "c:\\Users\\giuli\\Repositories\\aee_2425\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giuli\\AppData\\Local\\Temp\\ipykernel_29256\\35471574.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_cv, y_val_cv = y_train[train_idx], y_train[val_idx]\n",
      "c:\\Users\\giuli\\Repositories\\aee_2425\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giuli\\AppData\\Local\\Temp\\ipykernel_29256\\35471574.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_cv, y_val_cv = y_train[train_idx], y_train[val_idx]\n",
      "c:\\Users\\giuli\\Repositories\\aee_2425\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giuli\\AppData\\Local\\Temp\\ipykernel_29256\\35471574.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_cv, y_val_cv = y_train[train_idx], y_train[val_idx]\n",
      "c:\\Users\\giuli\\Repositories\\aee_2425\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "Mean MSE across all folds: 359.8757\n",
      "Variance (Standard Deviation) of MSE across folds: 195.1798\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Define the LSTM model\n",
    "def lstm_model(X_train_scaled, y_train):\n",
    "    \"\"\"\n",
    "    Builds and trains an LSTM model using the training data.\n",
    "\n",
    "    Parameters:\n",
    "        X_train_scaled (np.ndarray): Scaled input training data.\n",
    "        y_train (np.ndarray): Target training data.\n",
    "\n",
    "    Returns:\n",
    "        Sequential: Trained LSTM model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, activation='relu', return_sequences=True, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=60, activation='relu', return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(units=80, activation='relu', return_sequences=True))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(LSTM(units=120, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=1))  # Output layer for single prediction\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)  # Train with verbose=0 to suppress output\n",
    "    return model\n",
    "\n",
    "# Step 7: Apply K-Fold Cross Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
    "mean_errors = []\n",
    "std_errors = []\n",
    "\n",
    "# Track the MSE for each fold\n",
    "for train_idx, val_idx in kf.split(X_train_scaled):\n",
    "    X_train_cv, X_val_cv = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "    y_train_cv, y_val_cv = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    # Train LSTM model\n",
    "    model = lstm_model(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # Make predictions on the validation fold\n",
    "    y_pred = model.predict(X_val_cv)\n",
    "    \n",
    "    # Calculate Mean Squared Error for this fold\n",
    "    mse = mean_squared_error(y_val_cv, y_pred)\n",
    "    mean_errors.append(mse)\n",
    "\n",
    "# Calculate mean error (MSE) and variance (standard deviation) across all folds\n",
    "mean_mse = np.mean(mean_errors)\n",
    "std_mse = np.std(mean_errors)\n",
    "\n",
    "print(f\"Mean MSE across all folds: {mean_mse:.4f}\")\n",
    "print(f\"Variance (Standard Deviation) of MSE across folds: {std_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = pd.concat([test, train], sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Prediction'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTilted Irradiance (Adjusted)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mplot(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m15\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\giuli\\Repositories\\aee_2425\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\giuli\\Repositories\\aee_2425\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\giuli\\Repositories\\aee_2425\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Prediction'] not in index\""
     ]
    }
   ],
   "source": [
    "_ = all[['Tilted Irradiance (Adjusted)', 'Prediction']].plot(figsize=(15,15))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the threshold for the top 10% of 'Tilted Irradiance (Adjusted)'\n",
    "top_10_percent_threshold = all['Tilted Irradiance (Adjusted)'].quantile(0.70)\n",
    "\n",
    "# Step 2: Filter the data to only include the top 10% based on 'Tilted Irradiance (Adjusted)'\n",
    "top_10_percent_data = all[all['Tilted Irradiance (Adjusted)'] >= top_10_percent_threshold]\n",
    "\n",
    "# Step 3: Plot the filtered data as a line plot for actual and predicted data\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the actual data (blue)\n",
    "plt.plot(top_10_percent_data.index, top_10_percent_data['Tilted Irradiance (Adjusted)'], label='Actual', color='blue')\n",
    "\n",
    "# Plot the predicted data (red)\n",
    "plt.plot(top_10_percent_data.index, top_10_percent_data['Prediction'], label='Prediction', color='red')\n",
    "\n",
    "# Optional: Add titles, labels, and a legend\n",
    "plt.title(\"Top 30% of 'Tilted Irradiance (Adjusted)' vs Prediction\")\n",
    "plt.xlabel(\"Datetime\")  # or \"Index\" if the index is not datetime\n",
    "plt.ylabel(\"Irradiance / Prediction\")\n",
    "plt.legend()\n",
    "\n",
    "# Rotate x-axis labels if necessary for readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot with tight layout for spacing\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the forecast with the actuals\n",
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(5)\n",
    "f.set_figwidth(15)\n",
    "\n",
    "# Plot actual vs predicted MW values, with distinct line styles\n",
    "_ = all[['Prediction', 'Tilted Irradiance (Adjusted)']].plot(ax=ax,\n",
    "                                                style=['-', '.'],\n",
    "                                                color=['red', 'blue'])  # Red for Prediction, Blue for Actuals\n",
    "\n",
    "# Set x-axis bounds to zoom in on January 2015\n",
    "ax.set_xlim(pd.to_datetime('2019-11-01'), pd.to_datetime('2019-12-01'))\n",
    "\n",
    "# Set y-axis limits to match the range from 0 to 60000\n",
    "#ax.set_ylim(0, 60000)\n",
    "\n",
    "# Add a title for the plot\n",
    "plt.suptitle('December 2019 Forecast vs Actuals')\n",
    "\n",
    "# Optional: Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Prediction'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\giuli\\Repositories\\aee_2425\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Prediction'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mape\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m mape_value \u001b[38;5;241m=\u001b[39m mean_absolute_percentage_error(y_true\u001b[38;5;241m=\u001b[39mtest[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTilted Irradiance (Adjusted)\u001b[39m\u001b[38;5;124m'\u001b[39m], y_pred\u001b[38;5;241m=\u001b[39m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAPE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmape_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Your true and predicted values\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\giuli\\Repositories\\aee_2425\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\giuli\\Repositories\\aee_2425\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Prediction'"
     ]
    }
   ],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    \"\"\"Calculates MAPE given y_true and y_pred, handling zero values in y_true.\"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    # Mask where y_true is zero or NaN\n",
    "    valid_mask = (y_true != 0) & ~np.isnan(y_true)\n",
    "    \n",
    "    # Apply the mask to both y_true and y_pred\n",
    "    y_true_valid = y_true[valid_mask]\n",
    "    y_pred_valid = y_pred[valid_mask]\n",
    "    \n",
    "    # If there are no valid points, return NaN or some other indicator (e.g., inf)\n",
    "    if len(y_true_valid) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # Calculate the MAPE only on valid (non-zero, non-NaN) values\n",
    "    mape = np.mean(np.abs((y_true_valid - y_pred_valid) / y_true_valid)) * 100\n",
    "    \n",
    "    return mape\n",
    "\n",
    "# Example usage:\n",
    "mape_value = mean_absolute_percentage_error(y_true=test['Tilted Irradiance (Adjusted)'], y_pred=test['Prediction'])\n",
    "print(f\"MAPE: {mape_value:.2f}%\")\n",
    "\n",
    "# Your true and predicted values\n",
    "y_true = test['Tilted Irradiance (Adjusted)']\n",
    "y_pred = test['Prediction']\n",
    "\n",
    "# Ensure that both y_true and y_pred are arrays or series of the same length\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n",
    "# R-squared (R²) - how well the model explains the variance\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "print(f\"R-squared (R²): {r2:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Model Evaluation and Conclusions\n",
    "\n",
    "## Model Performance Metrics:\n",
    "\n",
    "The evaluation of the model was done using several performance metrics:\n",
    "\n",
    "- **Mean Absolute Percentage Error (MAPE)**: 16.21%\n",
    "- **Mean Absolute Error (MAE)**: 10.18\n",
    "- **Mean Squared Error (MSE)**: 385.89\n",
    "- **Root Mean Squared Error (RMSE)**: 19.64\n",
    "- **R-squared (R²)**: 0.99\n",
    "\n",
    "## Interpretation of Results:\n",
    "\n",
    "1. **MAPE (16.21%)**:\n",
    "   - The Mean Absolute Percentage Error (MAPE) indicates that the model's predictions deviate from the actual values by approximately 16.21% on average. A MAPE value below 20% is typically considered good in predictive modeling, particularly for time-series forecasts. This suggests the model is performing reasonably well.\n",
    "\n",
    "2. **MAE (10.18)**:\n",
    "   - The Mean Absolute Error (MAE) measures the average magnitude of the errors in a set of predictions, without considering their direction. An MAE of 10.18 means that, on average, the model's predictions are off by around 10.18 units (MW) from the actual values.\n",
    "\n",
    "3. **MSE (385.89) & RMSE (19.64)**:\n",
    "   - The Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) provide a sense of the magnitude of the errors, with RMSE being particularly useful for understanding the scale of the error in the original units. The relatively low RMSE (19.64) indicates that, while there are errors, they are not large in the context of the problem.\n",
    "\n",
    "4. **R-squared (0.99)**:\n",
    "   - The R-squared value of 0.99 indicates that the model is able to explain 99% of the variance in the target variable, which is excellent. A high R² value suggests that the model fits the data very well and is likely capturing the underlying patterns in the time series accurately.\n",
    "\n",
    "## Conclusion:\n",
    "\n",
    "The model performs very well, with a high R-squared value, indicating that it can explain most of the variance in the data. The MAPE value of 16.21% is reasonable, suggesting that the model has a good predictive performance, though there is still room for improvement. The MAE, MSE, and RMSE values suggest that the model's predictions are fairly close to the actual values, with relatively small errors. \n",
    "\n",
    "Overall, the LSTM model appears to be a strong fit for predicting the solar energy generation based on the provided features.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
